{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv('..//data//processed_datasets//processed_datasets.csv')\n",
    "df_full.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "df_full['date'] = pd.to_datetime(df_full['date'])\n",
    "df_full = df_full.set_index(\"date\")\n",
    "df_full = df_full.asfreq('D')\n",
    "df_full = df_full.sort_index()\n",
    "df_full.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because it is tree based algorithm,we won't use cyclical encoding\n",
    "cyclical_encoding_columns = [\n",
    "  'dayofweek_sin',\n",
    "  'dayofweek_cos',\n",
    "  'quarter_sin',\n",
    "  'quarter_cos',\n",
    "  'month_sin',\n",
    "  'month_cos',\n",
    "  'dayofyear_sin',\n",
    "  'dayofyear_cos',\n",
    "  'dayofmonth_sin',\n",
    "  'dayofmonth_cos',\n",
    "  'weekofyear_sin',\n",
    "  'weekofyear_cos'\n",
    "]\n",
    "\n",
    "# Drop columns\n",
    "df_full = df_full.drop(cyclical_encoding_columns, axis=1)\n",
    "df_full.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xy_multiple_input_single_output(\n",
    "    df,\n",
    "    target_column,\n",
    "    exog_columns,\n",
    "    window_size,\n",
    "    prediction_horizon,\n",
    "    flatten=False,\n",
    "    return_shape=False\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Transform time series data into supervised tasks with input-output pairs.\n",
    "\n",
    "    Parameters:\n",
    "      - df (pandas.DataFrame): The DataFrame containing the time series data.\n",
    "      - target_column (str): The name of the target column for prediction.\n",
    "      - exog_columns (list): A list of column names representing exogenous variables.\n",
    "      - window_size (int): The size of the lookback window (past observations) to create inputs in input-output pairs \n",
    "      - prediction_horizon (int): The number of steps ahead to predict.\n",
    "      - flatten (bool, optional): Whether to flatten the inputs of the input-output pairs created (default is False).\n",
    "      - return_shape (bool, optional): Whether to print and return the shapes of input and output arrays (default is False).\n",
    "\n",
    "    Returns:\n",
    "      - tuple or None: A tuple containing input data and corresponding output data if flatten is False, \n",
    "                   otherwise, flattened input data and output data. If return_shape is True, \n",
    "                   prints and returns the shapes of input and output arrays in input-output pairs.\n",
    "    \"\"\"\n",
    "    exog_vars = df[exog_columns]\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(0, len(df) - window_size - prediction_horizon + 1):\n",
    "        x_window = df.iloc[i:(i + window_size)][target_column].values\n",
    "        exog_window = exog_vars.iloc[i:(i + window_size)].values  # Extract the corresponding exogenous window\n",
    "        # Reshape x_window to have 2 dimensions\n",
    "        x_window = np.atleast_2d(x_window).T\n",
    "        # Stack the exogenous variable horizontally\n",
    "        x_window = np.hstack((x_window, exog_window))\n",
    "        x.append(x_window)\n",
    "        y.append(df.iloc[(i + window_size):(i + window_size + prediction_horizon)][target_column].values)\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if flatten:\n",
    "      n_input = x.shape[1] * x.shape[2]\n",
    "      x_flattened = x.reshape((x.shape[0], n_input))\n",
    "\n",
    "      if return_shape:\n",
    "        print(f'x shape: {x_flattened.shape}')\n",
    "        print(f'y shape: {y.shape}')\n",
    "\n",
    "      return x_flattened, y\n",
    "\n",
    "    else:\n",
    "      if return_shape:\n",
    "        print(f'x shape: {x.shape}')\n",
    "        print(f'y shape: {y.shape}')\n",
    "\n",
    "      return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single_fold(train_set, n_fold, ith_fold, test_size, lookback_window):\n",
    "    \"\"\"\n",
    "    Create subsets of data including three dataframes including the subsets for training, evaluating, and lookback values used for making predictions into the future \n",
    "    \n",
    "    Parameters:\n",
    "      - train_set (pd.DataFrame): The input dataframe from which subsets will be created\n",
    "      - n_fold (int): A total number of subsets to be created \n",
    "      - ith_fold (int): A current index of subset in n_fold \n",
    "      - test_size (int): The number of steps ahead to predict (also the size of evaluation set in each subset)\n",
    "      - lookback_window (int): The size of the lookback window (past observations) to include\n",
    "    \n",
    "    Returns:\n",
    "        - tuple: A tuple contains three dataframes including the subsets for training, evaluating, and lookback values used for making predictions into the future \n",
    "    \"\"\"\n",
    "    # Calculate the start and end indices for the test set of the current fold\n",
    "    start_test_idx = - test_size * (n_fold - ith_fold + 1)\n",
    "    end_test_idx = start_test_idx + test_size\n",
    "    lookback_test_idx = start_test_idx - lookback_window\n",
    "\n",
    "    # Extract the train set for the current fold (excluding the test set)\n",
    "    fold_train_set = train_set.iloc[:start_test_idx]\n",
    "\n",
    "    # Extract the test set for the current fold\n",
    "    if ith_fold == n_fold:\n",
    "      fold_test_set = train_set.iloc[start_test_idx:]\n",
    "      fold_test_lookback = train_set.iloc[lookback_test_idx:]\n",
    "    else:\n",
    "      fold_test_lookback = train_set.iloc[lookback_test_idx:end_test_idx]\n",
    "      fold_test_set = train_set.iloc[start_test_idx:end_test_idx]\n",
    "\n",
    "\n",
    "    return fold_train_set, fold_test_set, fold_test_lookback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_forecast_bias(pred_series, actual_series):\n",
    "    \"\"\" \n",
    "    Forecast Bias (FB)\n",
    "\n",
    "    Parameters\n",
    "        - actual_series (pd.Series): The time series of actual values  \n",
    "        - pred_series (pd.Series): The time series of predicted values.\n",
    "\n",
    "    Returns\n",
    "        - float: The Forecast Bias \n",
    "    \"\"\"\n",
    "\n",
    "    y_true, y_pred = actual_series, pred_series\n",
    "    \n",
    "    y_true_sum, y_pred_sum = np.sum(y_true), np.sum(y_pred)\n",
    "    # raise_if_not(y_true_sum > 0, 'The series of actual value cannot sum to zero when computing OPE.', logger)\n",
    "    return ((y_pred_sum - y_true_sum) / len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_xgb_full(data_train, data_test, target_column, exog_column, window_size, horizon, xgb_params=None):\n",
    "    \"\"\"\n",
    "    Run XGBoost model for time series forecasting.\n",
    "\n",
    "    Parameters:\n",
    "        - data_train (pandas.DataFrame): The DataFrame containing the training data.\n",
    "        - data_test (pandas.DataFrame): The DataFrame containing the testing data.\n",
    "        - target_column (str): The name of the target column for prediction.\n",
    "        - exog_column (list): A list of column names representing exogenous variables.\n",
    "        - window_size (int): The size of the lookback window (past observations) to create inputs in input-output pairs \n",
    "        - horizon (int): The number of steps ahead to predict.\n",
    "        - xgb_params (dict, optional): Dictionary of parameters to configure the XGBoost (default is None).\n",
    "\n",
    "    Returns:\n",
    "        - tuple: A tuple containing the following elements:\n",
    "            - A dictionary containing evaluation metrics (MAE, RMSE, MAPE, sMAPE, forecast bias).\n",
    "            - A DataFrame containing forecasted and actual values.\n",
    "            - Trained XGBoost model.\n",
    "    \"\"\"\n",
    "    ## Create input-output pairs for training model\n",
    "    train_x, train_y = create_xy_multiple_input_single_output(\n",
    "        df=data_train,\n",
    "        target_column=target_column,\n",
    "        exog_columns=exog_column,\n",
    "        window_size=window_size,\n",
    "        prediction_horizon=horizon,\n",
    "        flatten=True,\n",
    "        return_shape=True\n",
    "    )\n",
    "    \n",
    "    # Create input-output pairs for testing \n",
    "    test_x, test_y = create_xy_multiple_input_single_output(\n",
    "        df=data_test,\n",
    "        target_column=target_column,\n",
    "        exog_columns=exog_column,\n",
    "        window_size=window_size,\n",
    "        prediction_horizon=horizon,\n",
    "        flatten=True,\n",
    "        return_shape=True\n",
    "    )\n",
    "    \n",
    "    # Modelling \n",
    "    lst_col = []\n",
    "    lst_col.append(target_column)\n",
    "    lst_col = lst_col + exog_column\n",
    "\n",
    "    feature_name_list = []\n",
    "    for i in range(window_size, 0, -1):\n",
    "        feature_name_list += [f'{col}_lag_{str(i)}' for col in lst_col]\n",
    "    if xgb_params == None:\n",
    "        model = MultiOutputRegressor(xgb.XGBRegressor(random_state=42))\n",
    "    else:\n",
    "        model = MultiOutputRegressor(xgb.XGBRegressor(**xgb_params, random_state=42))\n",
    "\n",
    "    model.fit(train_x, train_y)\n",
    "    forecast = model.predict(test_x)\n",
    "\n",
    "    # Return forecasted and actual values dataframe \n",
    "    df_result = data_test[-horizon:][[target_column]]\n",
    "    df_result['Forecast'] = forecast[0]\n",
    "\n",
    "    # Calculate metrics based on the specified metric\n",
    "    metric_eval_dict = {}\n",
    "    target_series = data_test[-horizon:][target_column]\n",
    "    metric_eval_dict['mae'] = np.mean(np.abs(forecast[0] - target_series)) #mae:\n",
    "    metric_eval_dict['rmse'] = np.sqrt(np.mean((forecast[0] - target_series)**2)) #rmse\n",
    "    metric_eval_dict['mape'] = np.mean(np.abs((forecast[0] - target_series) / target_series)) * 100 #mape\n",
    "    metric_eval_dict['smape'] = 2 * np.mean(np.abs(forecast[0] - target_series) / (np.abs(forecast[0]) + np.abs(target_series))) * 100 #smape\n",
    "    metric_eval_dict['forecast_bias'] = calculate_forecast_bias(forecast[0], target_series)\n",
    "    \n",
    "    return metric_eval_dict, df_result, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_feature_importance(model, n_limit, target_column, exog_columns, window_size):\n",
    "    \"\"\"\n",
    "    Plot feature importance for a XGBoost model.\n",
    "\n",
    "    Parameters:\n",
    "        - model: The trained LightGBM model.\n",
    "        - n_limit (int): The number of features to plot with highest importance values.\n",
    "        - target_column (str): The name of the target column for prediction.\n",
    "        - exog_columns (list): A list of column names representing exogenous variables.\n",
    "        - window_size (int): The size of the lookback window (past observations) \n",
    "\n",
    "    Returns:\n",
    "        - None\n",
    "    \"\"\"\n",
    "    lst_col = [target_column] + exog_columns\n",
    "    feature_name_list = [f'{col}_lag_{str(i)}' for col in lst_col for i in range(window_size, 0, -1)]\n",
    "\n",
    "    # Set feature names for each booster\n",
    "    for estimator in model.estimators_:\n",
    "        if hasattr(estimator, 'get_booster'):\n",
    "            estimator.get_booster().feature_names = feature_name_list\n",
    "\n",
    "    # Get feature importance scores from the first estimator\n",
    "    feature_important = model.estimators_[0].get_booster().get_score(importance_type='weight')\n",
    "\n",
    "    # Normalize feature importance scores\n",
    "    total_importance = sum(feature_important.values())\n",
    "    normalized_importance = {key: value / total_importance for key, value in feature_important.items()}\n",
    "\n",
    "    # Sort the features by importance and get the indices of the top n_limit features\n",
    "    sorted_features = sorted(normalized_importance.items(), key=lambda x: x[1], reverse=True)[:n_limit][::-1]\n",
    "    features, importance = zip(*sorted_features)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(features)), importance, align='center')\n",
    "    plt.yticks(range(len(features)), features)\n",
    "    plt.xlabel('Normalized Feature Importance')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title('Top Feature Importance Plot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xgb(data_train, data_test, target_column, exog_column, window_size, horizon, metric, xgb_params=None):\n",
    "    \"\"\"\n",
    "    Run XGBoost model for time series forecasting. \n",
    "    This is a simple implementation which only returns a value of a certain error metric \n",
    "\n",
    "    Parameters:\n",
    "        - data_train (pandas.DataFrame): The DataFrame containing the training data.\n",
    "        - data_test (pandas.DataFrame): The DataFrame containing the testing data.\n",
    "        - target_column (str): The name of the target column for prediction.\n",
    "        - exog_column (list): A list of column names representing exogenous variables.\n",
    "        - window_size (int): The size of the lookback window (past observations) to create inputs in input-output pairs \n",
    "        - horizon (int): The number of steps ahead to predict.\n",
    "        - metric (str): Select a metric of which a value will be returned. Metrics include MAE, RMSE, MAPE, sMAPE\n",
    "        - xgb_params (dict, optional): Dictionary of parameters to configure the XGBoost (default is None).\n",
    "\n",
    "    Returns:\n",
    "        - float: A value of the metric chosen will be returned \n",
    "    \"\"\"\n",
    "    # Create data train\n",
    "    train_x, train_y = create_xy_multiple_input_single_output(\n",
    "        df=data_train,\n",
    "        target_column=target_column,\n",
    "        exog_columns=exog_column,\n",
    "        window_size=window_size,\n",
    "        prediction_horizon=horizon,\n",
    "        flatten=True,\n",
    "        return_shape=True\n",
    "    )\n",
    "    \n",
    "    # Create data test \n",
    "    test_x, test_y = create_xy_multiple_input_single_output(\n",
    "        df=data_test,\n",
    "        target_column=target_column,\n",
    "        exog_columns=exog_column,\n",
    "        window_size=window_size,\n",
    "        prediction_horizon=horizon,\n",
    "        flatten=True,\n",
    "        return_shape=True\n",
    "    )\n",
    "    \n",
    "    # Modelling \n",
    "    lst_col = []\n",
    "    lst_col.append(target_column)\n",
    "    lst_col = lst_col + exog_column\n",
    "\n",
    "    feature_name_list = []\n",
    "    for i in range(window_size, 0, -1):\n",
    "        feature_name_list += [f'{col}_lag_{str(i)}' for col in lst_col]\n",
    "    if xgb_params == None:\n",
    "        model = MultiOutputRegressor(xgb.XGBRegressor(random_state=42), n_jobs = -1)\n",
    "    else:\n",
    "        model = MultiOutputRegressor(xgb.XGBRegressor(**xgb_params, random_state=42), n_jobs = -1)\n",
    "\n",
    "    model.fit(train_x, train_y)\n",
    "    forecast = model.predict(test_x)\n",
    "\n",
    "    # Calculate metrics based on the specified metric\n",
    "    metric_val = None\n",
    "    metric = 'mae'  # Change this to 'rmse', 'mape', or 'smape' for different metrics\n",
    "    if metric == 'mae':\n",
    "        metric_val = np.mean(np.abs(forecast - test_y))\n",
    "    elif metric == 'rmse':\n",
    "        metric_val = np.sqrt(np.mean((forecast - test_y)**2))\n",
    "    elif metric == 'mape':\n",
    "        metric_val = np.mean(np.abs((forecast - test_y) / test_y)) * 100\n",
    "    elif metric == 'smape':\n",
    "        metric_val = 2 * np.mean(np.abs(forecast - test_y) / (np.abs(forecast) + np.abs(test_y))) * 100\n",
    "    \n",
    "    return metric_val "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grid_search_combinations(param_distributions):\n",
    "  \"\"\"\n",
    "  Generates a list of dictionaries representing all possible combinations of values\n",
    "  from the given parameter distributions.\n",
    "\n",
    "  Parameters:\n",
    "      - param_distributions: A dictionary where keys are parameter names and values are\n",
    "                          lists of possible values for each parameter.\n",
    "\n",
    "  Returns:\n",
    "      - A list of dictionaries, where each dictionary represents a unique combination\n",
    "      of parameter values.\n",
    "  \"\"\"\n",
    "\n",
    "  combinations = []\n",
    "  for key, values in param_distributions.items():\n",
    "    if combinations:\n",
    "      # Combine existing combinations with each value for the current key\n",
    "      new_combinations = []\n",
    "      for value in values:\n",
    "        for combination in combinations:\n",
    "          new_combination = {**combination, key: value}\n",
    "          new_combinations.append(new_combination)\n",
    "      combinations = new_combinations\n",
    "    else:\n",
    "      # For the first key, each value becomes a separate combination\n",
    "      combinations = [{key: value} for value in values]\n",
    "  return combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def cv_xgb(\n",
    "    train_df,\n",
    "    target_column,\n",
    "    exog_columns,\n",
    "    horizon,\n",
    "    n_folds,\n",
    "    param_grid,\n",
    "    eval_metric='mae',\n",
    "    method='random search',\n",
    "    n_iter=5,\n",
    "    return_result=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform cross-validation with XGBoost for time-series forecasting.\n",
    "    Print best hyperparameter combination \n",
    "\n",
    "    Parameters:\n",
    "      - train_df (pandas.DataFrame): The DataFrame containing the training data.\n",
    "      - target_column (str): The name of the target column for prediction.\n",
    "      - exog_columns (list): A list of column names representing exogenous variables.\n",
    "      - horizon (int): The number of steps ahead to predict.\n",
    "      - n_folds (int): The number of folds for cross-validation.\n",
    "      - param_grid (dict): A dictionary specifying the hyperparameter grid.\n",
    "      - eval_metric (str, optional): The evaluation metric to use for model performance (default is 'mae').\n",
    "      - method (str, optional): The method for parameter search, either 'random search' or 'grid search' (default is 'random search').\n",
    "      - n_iter (int, optional): The number of iterations for random search (default is 5).\n",
    "      - return_result (bool, optional): Whether to return the results in a DataFrame (default is True).\n",
    "\n",
    "    Returns:\n",
    "      - pandas.DataFrame or None: A DataFrame containing the evaluation metric scores for each parameter combination if return_result is True, otherwise, None\n",
    "    \"\"\"\n",
    "\n",
    "    # Take in search space and create combinations of parameters \n",
    "    if method == 'random search':\n",
    "      full_params_combinations = generate_grid_search_combinations(param_grid)\n",
    "      # Set random seed for reproducibility\n",
    "      random.seed(42)\n",
    "      # Randomly select n values from the original list\n",
    "      params_combinations = random.sample(full_params_combinations, n_iter)\n",
    "      \n",
    "    if method == 'grid search':\n",
    "      params_combinations = generate_grid_search_combinations(param_grid)\n",
    "\n",
    "    # Initialize params list and score\n",
    "    lst_params_combi = []\n",
    "    lst_cv_performance_scores = []\n",
    "\n",
    "    # Iterate over parameter combinations\n",
    "    for param_combination in params_combinations:\n",
    "      \n",
    "      # Initialize a list to store evaluation values of n_fold\n",
    "      performance_scores = []\n",
    "\n",
    "      # Extract window_size param \n",
    "      window_size = param_combination['lookback_window']\n",
    "      # Remove 'lookback_window' key and its value ot use in xgb model \n",
    "      param_combination.pop('lookback_window', None)\n",
    "\n",
    "      for ith_fold in range(1, n_folds+1, 1):\n",
    "\n",
    "        ith_fold_train, ith_fold_test, ith_fold_lookback = create_single_fold(\n",
    "            train_set=train_df,\n",
    "            n_fold=n_folds,\n",
    "            ith_fold=ith_fold,\n",
    "            test_size=horizon,\n",
    "            lookback_window=window_size\n",
    "            )\n",
    "\n",
    "        model_performance = run_xgb(\n",
    "            data_train=ith_fold_train, \n",
    "            data_test=ith_fold_lookback, \n",
    "            target_column=target_column, \n",
    "            exog_column=exog_columns, \n",
    "            window_size=window_size, \n",
    "            horizon=horizon, \n",
    "            metric=eval_metric, \n",
    "            xgb_params=param_combination\n",
    "        )\n",
    "\n",
    "        # Append the performance value at ith fold \n",
    "        performance_scores.append(model_performance)\n",
    "        \n",
    "      # Save the combination \n",
    "      param_combination['lookback_window'] = window_size\n",
    "      lst_params_combi.append(param_combination)\n",
    "      \n",
    "      # Calculate the average values after n_fold iteration for the current param combination\n",
    "      avg_performance_scores = np.average(performance_scores)\n",
    "      # Append to the list \n",
    "      lst_cv_performance_scores.append(avg_performance_scores)\n",
    "\n",
    "\n",
    "    # Dataframe of params and performance\n",
    "    summary_df = pd.DataFrame(\n",
    "            {\n",
    "              'params': lst_params_combi,\n",
    "              'eval_metric': lst_cv_performance_scores,\n",
    "            }\n",
    "            )\n",
    "    summary_df = summary_df.sort_values(by=['eval_metric'], ascending=True)\n",
    "\n",
    "    print(f\"Best params: {summary_df.head(1)['params']} \\nBest performance: {summary_df.head(1)['eval_metric']}\")\n",
    "\n",
    "    if return_result:\n",
    "      return summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(df_result, actual_column, forecast_column, labels=['Actual Values', 'Forecast Values']):\n",
    "    \"\"\"\n",
    "    Plot actual and forecasted values from a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        - df_result (pandas.DataFrame): The DataFrame containing actual and forecasted values.\n",
    "        - actual_column (str): The name of the column containing actual values.\n",
    "        - forecast_column (str): The name of the column containing forecasted values.\n",
    "        - labels (list, optional): A list containing labels for actual and forecasted values (default is ['Actual Values', 'Forecast Values']).\n",
    "\n",
    "    Returns:\n",
    "        - None\n",
    "    \"\"\"   \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot selling_price\n",
    "    plt.plot(df_result.index, df_result[actual_column], label=labels[0])\n",
    "\n",
    "    # Plot direct forecast\n",
    "    plt.plot(df_result.index, df_result[forecast_column], label=labels[1])\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(f'{labels[0]} vs {labels[1]}')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target and exog columns\n",
    "TARGET = 'selling_price'\n",
    "EXOGS = df_full.columns.tolist()\n",
    "EXOGS.remove(TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constant\n",
    "WINDOW_SIZE = 31\n",
    "HORIZON = 31 \n",
    "HOLDOUT_SIZE = 310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data \n",
    "data_train = df_full.iloc[: -HORIZON-HOLDOUT_SIZE, :]\n",
    "data_holdout = df_full.iloc[-HORIZON-HOLDOUT_SIZE:-HORIZON, :]\n",
    "data_test  = df_full.iloc[-HORIZON:, :]\n",
    "data_lookback_test = df_full.iloc[-WINDOW_SIZE-HORIZON:, :]\n",
    "data_validation = df_full.iloc[-HORIZON-HOLDOUT_SIZE-WINDOW_SIZE:-HORIZON-HOLDOUT_SIZE+HORIZON, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the target column of each dataframe\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(data_train.index, data_train[TARGET], label='Train Data')\n",
    "plt.plot(data_holdout.index, data_holdout[TARGET], label='Holdout Data')\n",
    "plt.plot(data_test.index, data_test[TARGET], label='Test Data')\n",
    "plt.plot(data_lookback_test.index, data_lookback_test[TARGET], label='Lookback Test Data')\n",
    "plt.plot(data_validation.index, data_validation[TARGET], label='Validation Data')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Target Column')\n",
    "plt.title('Target Column Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_col = []\n",
    "lst_col.append(TARGET)\n",
    "lst_col = lst_col + EXOGS\n",
    "\n",
    "feature_name_list = []\n",
    "for i in range(WINDOW_SIZE, 0, -1):\n",
    "    feature_name_list += [f'{col}_lag_{str(i)}' for col in lst_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Simple Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost model with default hyperparameter values \n",
    "metric_res, result, model = run_xgb_full(\n",
    "    data_train=data_train, \n",
    "    data_test=data_validation, \n",
    "    target_column=TARGET, \n",
    "    exog_column=EXOGS, \n",
    "    window_size=31, \n",
    "    horizon=31, \n",
    "    xgb_params=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results of error metrics \n",
    "metric_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the forecast values \n",
    "plot_forecast(\n",
    "    df_result=result, \n",
    "    actual_column='selling_price', \n",
    "    forecast_column='Forecast', \n",
    "    labels=['Actual Values', 'Forecast Values']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance \n",
    "plot_feature_importance(\n",
    "    model=model, \n",
    "    n_limit=15, \n",
    "    target_column=TARGET, \n",
    "    exog_columns=EXOGS, \n",
    "    window_size=31\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define search space for hyperparameters\n",
    "param_distributions = {\n",
    "  'lookback_window': [31],\n",
    "  'eta': [0.2, 0.3, 0.4],\n",
    "  'n_estimators': [300, 400, 500, 600],\n",
    "  'max_depth': [5, 6, 7],\n",
    "  'colsample_bytree': [0.6, 0.8, 1],\n",
    "  'subsample': [0.6, 0.8, 0.1]\n",
    "}\n",
    "# Perform hyperparameter tuning using random search\n",
    "result_df = cv_xgb(\n",
    "    train_df=data_train,\n",
    "    target_column=TARGET,\n",
    "    exog_columns=EXOGS,\n",
    "    horizon=HORIZON,\n",
    "    n_folds=5,\n",
    "    param_grid=param_distributions,\n",
    "    eval_metric='mae',\n",
    "    method='random search',\n",
    "    n_iter=5,\n",
    "    return_result=True\n",
    ")\n",
    "\n",
    "# Save results of hypeparameter tuning stage to a dataframe \n",
    "result_df.to_csv(f\"tuning_xgb_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Tuned Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned params\n",
    "tuned_window = 31\n",
    "tuned_params = {\n",
    "    'eta': 0.2, \n",
    "    'n_estimators': 600, \n",
    "    'max_depth': 6,\n",
    "    'colsample_bytree': 0.8, \n",
    "    'subsample': 0.6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost model with optimal combination of hyperparameters \n",
    "tuned_metric_res, tuned_result, tuned_model= run_xgb_full(\n",
    "    data_train=data_train, \n",
    "    data_test=data_validation, \n",
    "    target_column=TARGET, \n",
    "    exog_column=EXOGS, \n",
    "    window_size=tuned_window, \n",
    "    horizon=HORIZON, \n",
    "    xgb_params=tuned_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display values of error metrics\n",
    "tuned_metric_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forecasted values\n",
    "plot_forecast(\n",
    "    df_result=tuned_result, \n",
    "    actual_column='selling_price', \n",
    "    forecast_column='Forecast', \n",
    "    labels=['Actual Values', 'Forecast Values']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "plot_feature_importance(\n",
    "    model=tuned_model, \n",
    "    n_limit=5, \n",
    "    target_column=TARGET, \n",
    "    exog_columns=EXOGS, \n",
    "    window_size=31\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Holdout Forecast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New df containing both training data (used as inputs) to forecast into the holdout set \n",
    "data_holdout_rolling = df_full[:-HORIZON]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "len(data_holdout_rolling) == len(data_train) + len(data_holdout)\n",
    "# True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "print(data_holdout.head(1).index)\n",
    "print(data_holdout.tail(1).index)\n",
    "print(data_holdout.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_time = 10\n",
    "\n",
    "index = []\n",
    "forecast_values = []\n",
    "\n",
    "for i in range(repeat_time, 0, -1):\n",
    "    \n",
    "    # Define train and test set \n",
    "    temp_train_data = data_holdout_rolling[:-HORIZON*i]    \n",
    "    # Forecast to the future in holdout\n",
    "    if i > 1:\n",
    "        temp_forecast_lookback_data = data_holdout_rolling[-HORIZON*i-WINDOW_SIZE:-HORIZON*i+HORIZON]\n",
    "    else:\n",
    "        temp_forecast_lookback_data = data_holdout_rolling[-HORIZON*i-WINDOW_SIZE:]\n",
    "        \n",
    "    # Refit the model and make forecast \n",
    "    holdout_metric_res, holdout_result, holdout_model= run_xgb_full(\n",
    "       data_train=temp_train_data, \n",
    "       data_test=temp_forecast_lookback_data, \n",
    "       target_column=TARGET, \n",
    "       exog_column=EXOGS, \n",
    "       window_size=WINDOW_SIZE, \n",
    "       horizon=HORIZON, \n",
    "       xgb_params=tuned_params\n",
    "    )\n",
    "    \n",
    "    index += holdout_result.index.tolist()\n",
    "    forecast_values += holdout_result['Forecast'].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to dictionary \n",
    "holdout_result_dict = {\n",
    "    'index': index,\n",
    "    'forecast_values_xgb': forecast_values\n",
    "}\n",
    "\n",
    "df_holdout_result = pd.DataFrame(holdout_result_dict)\n",
    "df_holdout_result = df_holdout_result.set_index('index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forecasts on Holdout set and actual values \n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(df_holdout_result.index, df_holdout_result['forecast_values_xgb'], label='Holdout Forecast')\n",
    "plt.plot(data_holdout.index, data_holdout['selling_price'], label='Actual Holdout')\n",
    "\n",
    "plt.title('Holdout forecast vs Actual')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Selling Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Test Period Forecast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data train to make forecast \n",
    "data_train_refit = df_full[:-HORIZON]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training period and testing period \n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(data_train_refit.index, data_train_refit['selling_price'], label='Training Refit')\n",
    "plt.plot(data_test.index, data_test['selling_price'], label='Test Period')\n",
    "# plt.plot(data_lookback_test.index, data_lookback_test['selling_price'], label='Lookback Test Period')\n",
    "\n",
    "plt.title('Training and Testing Period')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Selling Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit the model using training and holdout data and make forecast \n",
    "test_metric_res, test_result, test_model= run_xgb_full(\n",
    "       data_train=data_train_refit, \n",
    "       data_test=data_lookback_test, \n",
    "       target_column=TARGET, \n",
    "       exog_column=EXOGS, \n",
    "       window_size=WINDOW_SIZE, \n",
    "       horizon=HORIZON, \n",
    "       xgb_params=tuned_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display values of error metrics\n",
    "test_metric_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(test_result.index, test_result['selling_price'], label='Forecast Test Prices')\n",
    "plt.plot(test_result.index, test_result['Forecast'], label='Actual Test Prices')\n",
    "# plt.plot(data_lookback_test.index, data_lookback_test['selling_price'], label='Lookback Test Period')\n",
    "\n",
    "plt.title('Testing Actual vs Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Selling Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance \n",
    "plot_feature_importance(\n",
    "    model=test_model, \n",
    "    n_limit=5, \n",
    "    target_column=TARGET, \n",
    "    exog_columns=EXOGS, \n",
    "    window_size=31\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export result to dataframe\n",
    "test_predictions_to_dict = test_result.reset_index()\n",
    "dict_test_forecast = {\n",
    "    'index': test_predictions_to_dict['date'].tolist(),\n",
    "    'forecast_values_xgb': test_result['Forecast'].tolist()\n",
    "}\n",
    "\n",
    "df_test_forecast = pd.DataFrame(\n",
    "    dict_test_forecast\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Save Forecast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save holdout forecast values\n",
    "df_holdout_result.to_csv(f'..//results//xgboost_holdout_forecast.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test forecast values\n",
    "df_test_forecast.to_csv(f'..//results//xgboost_test_forecast.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tlcenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
